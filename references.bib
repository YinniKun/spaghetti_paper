@article{schwartzTooManyCellsIdentifiesVisualizes2020, title={TooManyCells identifies and visualizes relationships of single-cell clades}, volume={17}, rights={2020 The Author(s), under exclusive licence to Springer Nature America, Inc.}, ISSN={1548-7105}, DOI={10.1038/s41592-020-0748-5}, abstractNote={Identifying and visualizing transcriptionally similar cells is instrumental for accurate exploration of the cellular diversity revealed by single-cell transcriptomics. However, widely used clustering and visualization algorithms produce a fixed number of cell clusters. A fixed clustering ‘resolution’ hampers our ability to identify and visualize echelons of cell states. We developed TooManyCells, a suite of graph-based algorithms for efficient and unbiased identification and visualization of cell clades. TooManyCells introduces a visualization model built on a concept intentionally orthogonal to dimensionality-reduction methods. TooManyCells is also equipped with an efficient matrix-free divisive hierarchical spectral clustering different from prevalent single-resolution clustering methods. TooManyCells enables multiresolution and multifaceted exploration of single-cell clades. An advantage of this paradigm is the immediate detection of rare and common populations that outperforms popular clustering and visualization algorithms, as demonstrated using existing single-cell transcriptomic data sets and new data modeling drug-resistance acquisition in leukemic T cells.}, note={Citation Key: schwartzTooManyCellsIdentifiesVisualizes2020}, number={44}, journal={Nature Methods}, publisher={Nature Publishing Group}, author={Schwartz, Gregory W. and Zhou, Yeqiao and Petrovic, Jelena and Fasolino, Maria and Xu, Lanwei and Shaffer, Sydney M. and Pear, Warren S. and Vahedi, Golnaz and Faryabi, Robert B.}, year={2020}, month=apr, pages={405–413}, language={en} }

@article{itahana_role_2003,
  author       = {Itahana, Yoko and Singh, Jarnail and Sumida, Tomoki and Coppe, Jean-Philippe and Parrinello, Simona and Bennington, James L. and Desprez, Pierre-Yves},
  date         = {2003-11-11},
  journaltitle = {Cancer Res.},
  title        = {Role of Id-2 in the Maintenance of a Differentiated and Noninvasive Phenotype in Breast Cancer Cells1},
  issn         = {0008-5472},
  number       = {21},
  pages        = {7098--7105},
  volume       = {63},
  abstract     = {Id proteins are inhibitors of basic helix-loop-helix transcription factors and generally stimulate cell proliferation and inhibit differentiation. We have shown that ectopic expression of Id-1 in murine mammary epithelial cells resulted in loss of differentiation and gain of invasive and proliferative abilities. Moreover, Id-1 was highly expressed in aggressive breast cancer cells in culture and in biopsies from infiltrating carcinomas. In contrast to Id-1, we found that, in vitro and in vivo, Id-2 {mRNA} and protein were up-regulated as mammary epithelial cells lost proliferative capacity and initiated differentiation. We further determined that this up-regulation of Id-2 was a necessary step toward a fully differentiated phenotype in breast cells. Here we show that one of the components of the extracellular matrix network, laminin, is responsible for the increase in Id-2 expression during differentiation. We also show that Id-2 expression is inversely correlated with the rate of proliferation in murine mammary epithelial cells and that Id-2 is expressed at a higher level in differentiated human breast cancer cells in comparison with very aggressive and metastatic cells. When reintroduced in aggressive breast cancer cells, Id-2 is able to reduce their proliferative and invasive phenotypes and decrease their level of matrix metalloproteinase 9 secretion as well as increase syndecan-1 expression. Moreover, little Id-2 protein expression is detectable in human biopsies from aggressive and invasive carcinomas in comparison with in situ carcinomas. In conclusion, Id-2 expression not only follows a pattern opposite to that of Id-1 during mammary gland development and breast cancer progression but also appears to act as an important protein for the maintenance of a differentiated and noninvasive phenotype in normal and transformed breast cells.},
  file         = {Full Text PDF:/Users/Christie/Zotero/storage/3VE4HFWW/Itahana et al. - 2003 - Role of Id-2 in the Maintenance of a Differentiate.pdf:application/pdf;Snapshot:/Users/Christie/Zotero/storage/QS4XRSJE/Role-of-Id-2-in-the-Maintenance-of-a.html:text/html},
  fjournal     = {Cancer Research},
  shortjournal = {Cancer Research},
}

@article{stighall_high_2005,
  author       = {Stighall, Maria and Manetopoulos, Christina and Axelson, Håkan and Landberg, Göran},
  date         = {2005-04-07},
  journaltitle = {Int. J. Cancer},
  title        = {High {ID}2 protein expression correlates with a favourable prognosis in patients with primary breast cancer and reduces cellular invasiveness of breast cancer cells},
  doi          = {10.1002/ijc.20875},
  issn         = {1097-0215},
  note         = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/ijc.20875},
  number       = {3},
  pages        = {403--411},
  url          = {https://onlinelibrary.wiley.com/doi/abs/10.1002/ijc.20875},
  urldate      = {2023-04-30},
  volume       = {115},
  abstract     = {{ID} proteins have been implicated in the regulation of cell proliferation and differentiation in various cell types during normal development as well as in the formation of cancer. Our aim was to delineate the expression of {ID}2 by immunohistochemistry in primary breast cancer in order to detect potential associations with cell cycle regulatory proteins and/or clinicopathologic parameters. We further overexpressed {ID}2 in a breast cancer cell line to elaborate potential effects on proliferation and invasiveness. We observed large variations in {ID}2 expression in primary breast cancer, and the protein was localised to both the nucleus and cytoplasm. Interestingly, a high cytoplasmic {ID}2 protein level correlated with a favourable prognosis. Overexpressing {ID}2 in the {MDA}-{MB}-468 breast cancer cell line generated a marked cytoplasmic localisation of the protein and reduced the invasive capacity of cells. Modest enhancement of cell proliferation was further detected in {ID}2-overexpressing cells. In conclusion, {ID}2 protein expression varies substantially within primary breast tumours and high cytoplasmic levels of {ID}2 might reflect a less aggressive breast tumour phenotype. © 2005 Wiley-Liss, Inc.},
  file         = {Full Text PDF:/Users/Christie/Zotero/storage/BZBCXXZB/Stighall et al. - 2005 - High ID2 protein expression correlates with a favo.pdf:application/pdf;Snapshot:/Users/Christie/Zotero/storage/VFVKCJWT/ijc.html:text/html},
  fjournal     = {International Journal of Cancer},
  keywords     = {breast cancer, {ID}2, invasion, proliferation},
  langid       = {english},
}

@article{breitlingFEBSLetters2004,
  title = {Rank Products: A Simple, yet Powerful, New Method to Detect Differentially Regulated Genes in Replicated Microarray Experiments},
  shorttitle = {Rank Products},
  author = {Breitling, Rainer and Armengaud, Patrick and Amtmann, Anna and Herzyk, Pawel},
  date = {2004-08-27},
  journaltitle = {FEBS Letters},
  shortjournal = {FEBS Letters},
  volume = {573},
  number = {1-3},
  pages = {83--92},
  doi = {10.1016/j.febslet.2004.07.055}
}

@article{cyclegan2017,
      title={Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks}, 
      author={Jun-Yan Zhu and Taesung Park and Phillip Isola and Alexei A. Efros},
      year={2020},
      eprint={1703.10593},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1703.10593}, 
}

@article{hallucination,
      title={Distribution Matching Losses Can Hallucinate Features in Medical Image Translation}, 
      author={Joseph Paul Cohen and Margaux Luck and Sina Honari},
      year={2018},
      eprint={1805.08841},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1805.08841}, 
}

@article{ssim,
      title={Understanding SSIM}, 
      author={Jim Nilsson and Tomas Akenine-Möller},
      year={2020},
      eprint={2006.13846},
      archivePrefix={arXiv},
      primaryClass={eess.IV},
      url={https://arxiv.org/abs/2006.13846}, 
}

@article{LIVECell,
author={Edlund, Christoffer
and Jackson, Timothy R.
and Khalid, Nabeel
and Bevan, Nicola
and Dale, Timothy
and Dengel, Andreas
and Ahmed, Sheraz
and Trygg, Johan
and Sj{\"o}gren, Rickard},
title={LIVECell---A large-scale dataset for label-free live cell segmentation},
journal={Nature Methods},
year={2021},
month={Sep},
day={01},
volume={18},
number={9},
pages={1038-1045},
abstract={Light microscopy combined with well-established protocols of two-dimensional cell culture facilitates high-throughput quantitative imaging to study biological phenomena. Accurate segmentation of individual cells in images enables exploration of complex biological questions, but can require sophisticated imaging processing pipelines in cases of low contrast and high object density. Deep learning-based methods are considered state-of-the-art for image segmentation but typically require vast amounts of annotated data, for which there is no suitable resource available in the field of label-free cellular imaging. Here, we present LIVECell, a large, high-quality, manually annotated and expert-validated dataset of phase-contrast images, consisting of over 1.6 million cells from a diverse set of cell morphologies and culture densities. To further demonstrate its use, we train convolutional neural network-based models using LIVECell and evaluate model segmentation accuracy with a proposed a suite of benchmarks.},
issn={1548-7105},
doi={10.1038/s41592-021-01249-6},
url={https://doi.org/10.1038/s41592-021-01249-6}
}

@article{pannuke,
      title={PanNuke Dataset Extension, Insights and Baselines}, 
      author={Jevgenij Gamper and Navid Alemi Koohbanani and Ksenija Benes and Simon Graham and Mostafa Jahanifar and Syed Ali Khurram and Ayesha Azam and Katherine Hewitt and Nasir Rajpoot},
      year={2020},
      eprint={2003.10778},
      archivePrefix={arXiv},
      primaryClass={eess.IV},
      url={https://arxiv.org/abs/2003.10778}, 
}

@article{resnet,
      title={Deep Residual Learning for Image Recognition}, 
      author={Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
      year={2015},
      eprint={1512.03385},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1512.03385}, 
}

@article{adamw,
      title={Decoupled Weight Decay Regularization}, 
      author={Ilya Loshchilov and Frank Hutter},
      year={2019},
      eprint={1711.05101},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1711.05101}, 
}

@article {cellpose,
	author = {Stringer, Carsen and Pachitariu, Marius},
	title = {Cellpose3: one-click image restoration for improved cellular segmentation},
	elocation-id = {2024.02.10.579780},
	year = {2024},
	doi = {10.1101/2024.02.10.579780},
	publisher = {Cold Spring Harbor Laboratory},
	abstract = {Generalist methods for cellular segmentation have good out-of-the-box performance on a variety of image types. However, existing methods struggle for images that are degraded by noise, blurred or undersampled, all of which are common in microscopy. We focused the development of Cellpose3 on addressing these cases, and here we demonstrate substantial out-of-the-box gains in segmentation and image quality for noisy, blurry or undersampled images. Unlike previous approaches, which train models to restore pixel values, we trained Cellpose3 to output images that are well-segmented by a generalist segmentation model, while maintaining perceptual similarity to the target images. Furthermore, we trained the restoration models on a large, varied collection of datasets, thus ensuring good generalization to user images. We provide these tools as {\textquotedblleft}one-click{\textquotedblright} buttons inside the graphical interface of Cellpose as well as in the Cellpose API.Competing Interest StatementThe authors have declared no competing interest.},
	URL = {https://www.biorxiv.org/content/early/2024/02/12/2024.02.10.579780},
	eprint = {https://www.biorxiv.org/content/early/2024/02/12/2024.02.10.579780.full.pdf},
	journal = {bioRxiv}
}

@article{stardist,
   title={Cell Detection with Star-Convex Polygons},
   ISBN={9783030009342},
   ISSN={1611-3349},
   url={http://dx.doi.org/10.1007/978-3-030-00934-2_30},
   DOI={10.1007/978-3-030-00934-2_30},
   booktitle={Medical Image Computing and Computer Assisted Intervention – MICCAI 2018},
   publisher={Springer International Publishing},
   author={Schmidt, Uwe and Weigert, Martin and Broaddus, Coleman and Myers, Gene},
   year={2018},
   pages={265–273} }

@article{phikonv2,
      title={Phikon-v2, A large and public feature extractor for biomarker prediction}, 
      author={Alexandre Filiot and Paul Jacob and Alice Mac Kain and Charlie Saillard},
      year={2024},
      eprint={2409.09173},
      archivePrefix={arXiv},
      primaryClass={eess.IV},
      url={https://arxiv.org/abs/2409.09173}, 
}

@article{vit,
      title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale}, 
      author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
      year={2021},
      eprint={2010.11929},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2010.11929}, 
}

@software{hoptimus0,
  author = {Saillard, Charlie and Jenatton, Rodolphe and Llinares-López, Felipe and Mariet, Zelda and Cahané, David and Durand, Eric and Vert, Jean-Philippe},
  title = {H-optimus-0},
  url = {https://github.com/bioptimus/releases/tree/main/models/h-optimus/v0},
  year = {2024},
}

@article{c2c12,
author={Ker, Dai Fei Elmer
and Eom, Sungeun
and Sanami, Sho
and Bise, Ryoma
and Pascale, Corinne
and Yin, Zhaozheng
and Huh, Seung-il
and Osuna-Highley, Elvira
and Junkers, Silvina N.
and Helfrich, Casey J.
and Liang, Peter Yongwen
and Pan, Jiyan
and Jeong, Soojin
and Kang, Steven S.
and Liu, Jinyu
and Nicholson, Ritchie
and Sandbothe, Michael F.
and Van, Phu T.
and Liu, Anan
and Chen, Mei
and Kanade, Takeo
and Weiss, Lee E.
and Campbell, Phil G.},
title={Phase contrast time-lapse microscopy datasets with automated and manual cell tracking annotations},
journal={Scientific Data},
year={2018},
day={13},
volume={5},
number={1},
pages={180237},
abstract={Phase contrast time-lapse microscopy is a non-destructive technique that generates large volumes of image-based information to quantify the behaviour of individual cells or cell populations. To guide the development of algorithms for computer-aided cell tracking and analysis, 48 time-lapse image sequences, each spanning approximately 3.5 days, were generated with accompanying ground truths for C2C12 myoblast cells cultured under 4 different media conditions, including with fibroblast growth factor 2 (FGF2), bone morphogenetic protein 2 (BMP2), FGF2{\thinspace}+{\thinspace}BMP2, and control (no growth factor). The ground truths generated contain information for tracking at least 3 parent cells and their descendants within these datasets and were validated using a two-tier system of manual curation. This comprehensive, validated dataset will be useful in advancing the development of computer-aided cell tracking algorithms and function as a benchmark, providing an invaluable opportunity to deepen our understanding of individual and population-based cell dynamics for biomedical research.},
issn={2052-4463},
doi={10.1038/sdata.2018.237},
url={https://doi.org/10.1038/sdata.2018.237}
}

@article{pcm_background,
doi = {10.1088/0950-7671/19/5/302},
url = {https://dx.doi.org/10.1088/0950-7671/19/5/302},
year = {1942},
publisher = {},
volume = {19},
number = {5},
pages = {71},
author = {C R Burch and  J P P Stock},
title = {Phase-Contrast Microscopy},
journal = {Journal of Scientific Instruments},
abstract = {Slight optical non-homogeneities in certain transparent specimens are usually rendered visible by putting the specimen out of focus. One then sees not the non-homogeneities themselves, but the focal spots and lines they produce. Zernike's method of phase-contrast illumination, on the other hand, provides the maximum contrast when the specimen is accurately in focus, so that what is seen bears a closer resemblance to what is "really there". A simple method of adapting an ordinary microscope for phase-contrast is described, together with the preparation of a test-slide to check its performance. The method has proved helpful in studies of the interaction between leucocytes and mobile organisms.}
}

@article{phototoxicity,
author={Laissue, P. Philippe
and Alghamdi, Rana A.
and Tomancak, Pavel
and Reynaud, Emmanuel G.
and Shroff, Hari},
title={Assessing phototoxicity in live fluorescence imaging},
journal={Nature Methods},
year={2017},
day={01},
volume={14},
number={7},
pages={657-661},
abstract={This Commentary discusses the problem of phototoxicity in live imaging and suggests guidelines to improve its assessment and reporting.},
issn={1548-7105},
doi={10.1038/nmeth.4344},
url={https://doi.org/10.1038/nmeth.4344}
}

@article{he_stain,
author={Dunn, Catriona
and Brettle, David
and Cockroft, Martin
and Keating, Elizabeth
and Revie, Craig
and Treanor, Darren},
title={Quantitative assessment of H{\&}E staining for pathology: development and clinical evaluation of a novel system},
journal={Diagnostic Pathology},
year={2024},
day={23},
volume={19},
number={1},
pages={42},
abstract={Staining tissue samples to visualise cellular detail and tissue structure is at the core of pathology diagnosis, but variations in staining can result in significantly different appearances of the tissue sample. While the human visual system is adept at compensating for stain variation, with the growth of digital imaging in pathology, the impact of this variation can be more profound. Despite the ubiquity of haematoxylin and eosin staining in clinical practice worldwide, objective quantification is not yet available. We propose a method for quantitative haematoxylin and eosin stain assessment to facilitate quality assurance of histopathology staining, enabling truly quantitative quality control and improved standardisation.},
issn={1746-1596},
doi={10.1186/s13000-024-01461-w},
url={https://doi.org/10.1186/s13000-024-01461-w}
}

@article{survival_he_1,
author={Xu, Zhixin
and Lim, Seohoon
and Shin, Hong-Kyu
and Uhm, Kwang-Hyun
and Lu, Yucheng
and Jung, Seung-Won
and Ko, Sung-Jea},
title={Risk-aware survival time prediction from whole slide pathological images},
journal={Scientific Reports},
year={2022},
day={19},
volume={12},
number={1},
pages={21948},
abstract={Deep-learning-based survival prediction can assist doctors by providing additional information for diagnosis by estimating the risk or time of death. The former focuses on ranking deaths among patients based on the Cox model, whereas the latter directly predicts the survival time of each patient. However, it is observed that survival time prediction for the patients, particularly with close observation times, possibly has incorrect orders, leading to low prediction accuracy. Therefore, in this paper, we present a whole slide image (WSI)-based survival time prediction method that takes advantage of both the risk as well as time prediction. Specifically, we propose to combine these two approaches by extracting the risk prediction features and using them as guides for the survival time prediction. Considering the high resolution of WSIs, we extract tumor patches from WSIs using a pre-trained tumor classifier and apply the graph convolutional network to aggregate information across these patches effectively. Extensive experiments demonstrate that the proposed method significantly improves the time prediction accuracy when compared with direct prediction of the survival times without guidance and outperforms existing methods.},
issn={2045-2322},
doi={10.1038/s41598-022-26096-z},
url={https://doi.org/10.1038/s41598-022-26096-z}
}

@article{he_pdl1,
author={Shamai, Gil
and Livne, Amir
and Pol{\'o}nia, Ant{\'o}nio
and Sabo, Edmond
and Cretu, Alexandra
and Bar-Sela, Gil
and Kimmel, Ron},
title={Deep learning-based image analysis predicts PD-L1 status from H{\&}E-stained histopathology images in breast cancer},
journal={Nature Communications},
year={2022},
day={08},
volume={13},
number={1},
pages={6753},
abstract={Programmed death ligand-1 (PD-L1) has been recently adopted for breast cancer as a predictive biomarker for immunotherapies. The cost, time, and variability of PD-L1 quantification by immunohistochemistry (IHC) are a challenge. In contrast, hematoxylin and eosin (H{\&}E) is a robust staining used routinely for cancer diagnosis. Here, we show that PD-L1 expression can be predicted from H{\&}E-stained images by employing state-of-the-art deep learning techniques. With the help of two expert pathologists and a designed annotation software, we construct a dataset to assess the feasibility of PD-L1 prediction from H{\&}E in breast cancer. In a cohort of 3,376 patients, our system predicts the PD-L1 status in a high area under the curve (AUC) of 0.91 -- 0.93. Our system is validated on two external datasets, including an independent clinical trial cohort, showing consistent prediction performance. Furthermore, the proposed system predicts which cases are prone to pathologists miss-interpretation, showing it can serve as a decision support and quality assurance system in clinical practice.},
issn={2041-1723},
doi={10.1038/s41467-022-34275-9},
url={https://doi.org/10.1038/s41467-022-34275-9}
}

@article{he_disease_outcome,
author={Qaiser, Talha
and Lee, Ching-Yi
and Vandenberghe, Michel
and Yeh, Joe
and Gavrielides, Marios A.
and Hipp, Jason
and Scott, Marietta
and Reischl, Joachim},
title={Usability of deep learning and H{\&}E images predict disease outcome-emerging tool to optimize clinical trials},
journal={npj Precision Oncology},
year={2022},
day={15},
volume={6},
number={1},
pages={37},
abstract={Understanding factors that impact prognosis for cancer patients have high clinical relevance for treatment decisions and monitoring of the disease outcome. Advances in artificial intelligence (AI) and digital pathology offer an exciting opportunity to capitalize on the use of whole slide images (WSIs) of hematoxylin and eosin (H{\&}E) stained tumor tissue for objective prognosis and prediction of response to targeted therapies. AI models often require hand-delineated annotations for effective training which may not be readily available for larger data sets. In this study, we investigated whether AI models can be trained without region-level annotations and solely on patient-level survival data. We present a weakly supervised survival convolutional neural network (WSS-CNN) approach equipped with a visual attention mechanism for predicting overall survival. The inclusion of visual attention provides insights into regions of the tumor microenvironment with the pathological interpretation which may improve our understanding of the disease pathomechanism. We performed this analysis on two independent, multi-center patient data sets of lung (which is publicly available data) and bladder urothelial carcinoma. We perform univariable and multivariable analysis and show that WSS-CNN features are prognostic of overall survival in both tumor indications. The presented results highlight the significance of computational pathology algorithms for predicting prognosis using H{\&}E stained images alone and underpin the use of computational methods to improve the efficiency of clinical trial studies.},
issn={2397-768X},
doi={10.1038/s41698-022-00275-7},
url={https://doi.org/10.1038/s41698-022-00275-7}
}

@article{bleep,
      title={Spatially Resolved Gene Expression Prediction from H&E Histology Images via Bi-modal Contrastive Learning}, 
      author={Ronald Xie and Kuan Pang and Sai W. Chung and Catia T. Perciani and Sonya A. MacParland and Bo Wang and Gary D. Bader},
      year={2023},
      eprint={2306.01859},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2306.01859}, 
}

@misc{hest-1k,
      title={HEST-1k: A Dataset for Spatial Transcriptomics and Histology Image Analysis}, 
      author={Guillaume Jaume and Paul Doucet and Andrew H. Song and Ming Y. Lu and Cristina Almagro-Pérez and Sophia J. Wagner and Anurag J. Vaidya and Richard J. Chen and Drew F. K. Williamson and Ahrong Kim and Faisal Mahmood},
      year={2024},
      eprint={2406.16192},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2406.16192}, 
}

@article{tcga,
author={Chang, Kyle
and Creighton, Chad J.
and Davis, Caleb
and Donehower, Lawrence
and Drummond, Jennifer
and Wheeler, David
and Ally, Adrian
and Balasundaram, Miruna
and Birol, Inanc
and Butterfield, Yaron S. N.
and Chu, Andy
and Chuah, Eric
and Chun, Hye-Jung E.
and Dhalla, Noreen
and Guin, Ranabir
and Hirst, Martin
and Hirst, Carrie
and Holt, Robert A.
and Jones, Steven J. M.
and Lee, Darlene
and Li, Haiyan I.
and Marra, Marco A.
and Mayo, Michael
and Moore, Richard A.
and Mungall, Andrew J.
and Robertson, A. Gordon
and Schein, Jacqueline E.
and Sipahimalani, Payal
and Tam, Angela
and Thiessen, Nina
and Varhol, Richard J.
and Beroukhim, Rameen
and Bhatt, Ami S.
and Brooks, Angela N.
and Cherniack, Andrew D.
and Freeman, Samuel S.
and Gabriel, Stacey B.
and Helman, Elena
and Jung, Joonil
and Meyerson, Matthew
and Ojesina, Akinyemi I.
and Pedamallu, Chandra Sekhar
and Saksena, Gordon
and Schumacher, Steven E.
and Tabak, Barbara
and Zack, Travis
and Lander, Eric S.
and Bristow, Christopher A.
and Hadjipanayis, Angela
and Haseley, Psalm
and Kucherlapati, Raju
and Lee, Semin
and Lee, Eunjung
and Luquette, Lovelace J.
and Mahadeshwar, Harshad S.
and Pantazi, Angeliki
and Parfenov, Michael
and Park, Peter J.
and Protopopov, Alexei
and Ren, Xiaojia
and Santoso, Netty
and Seidman, Jonathan
and Seth, Sahil
and Song, Xingzhi
and Tang, Jiabin
and Xi, Ruibin
and Xu, Andrew W.
and Yang, Lixing
and Zeng, Dong
and Auman, J. Todd
and Balu, Saianand
and Buda, Elizabeth
and Fan, Cheng
and Hoadley, Katherine A.
and Jones, Corbin D.
and Meng, Shaowu
and Mieczkowski, Piotr A.
and Parker, Joel S.
and Perou, Charles M.
and Roach, Jeffrey
and Shi, Yan
and Silva, Grace O.
and Tan, Donghui
and Veluvolu, Umadevi
and Waring, Scot
and Wilkerson, Matthew D.
and Wu, Junyuan
and Zhao, Wei
and Bodenheimer, Tom
and Hayes, D. Neil
and Hoyle, Alan P.
and Jeffreys, Stuart R.
and Mose, Lisle E.
and Simons, Janae V.
and Soloway, Mathew G.
and Baylin, Stephen B.
and Berman, Benjamin P.
and Bootwalla, Moiz S.
and Danilova, Ludmila
and Herman, James G.
and Hinoue, Toshinori
and Laird, Peter W.
and Rhie, Suhn K.
and Shen, Hui
and Triche, Timothy
and Weisenberger, Daniel J.
and Carter, Scott L.
and Cibulskis, Kristian
and Chin, Lynda
and Zhang, Jianhua
and Getz, Gad
and Sougnez, Carrie
and Wang, Min
and Dinh, Huyen
and Doddapaneni, Harsha Vardhan
and Gibbs, Richard
and Gunaratne, Preethi
and Han, Yi
and Kalra, Divya
and Kovar, Christie
and Lewis, Lora
and Morgan, Margaret
and Morton, Donna
and Muzny, Donna
and Reid, Jeffrey
and Xi, Liu
and Cho, Juok
and DiCara, Daniel
and Frazer, Scott
and Gehlenborg, Nils
and Heiman, David I.
and Kim, Jaegil
and Lawrence, Michael S.
and Lin, Pei
and Liu, Yingchun
and Noble, Michael S.
and Stojanov, Petar
and Voet, Doug
and Zhang, Hailei
and Zou, Lihua
and Stewart, Chip
and Bernard, Brady
and Bressler, Ryan
and Eakin, Andrea
and Iype, Lisa
and Knijnenburg, Theo
and Kramer, Roger
and Kreisberg, Richard
and Leinonen, Kalle
and Lin, Jake
and Liu, Yuexin
and Miller, Michael
and Reynolds, Sheila M.
and Rovira, Hector
and Shmulevich, Ilya
and Thorsson, Vesteinn
and Yang, Da
and Zhang, Wei
and Amin, Samirkumar
and Wu, Chang-Jiun
and Wu, Chia-Chin
and Akbani, Rehan
and Aldape, Kenneth
and Baggerly, Keith A.
and Broom, Bradley
and Casasent, Tod D.
and Cleland, James
and Creighton, Chad
and Dodda, Deepti
and Edgerton, Mary
and Han, Leng
and Herbrich, Shelley M.
and Ju, Zhenlin
and Kim, Hoon
and Lerner, Seth
and Li, Jun
and Liang, Han
and Liu, Wenbin
and Lorenzi, Philip L.
and Lu, Yiling
and Melott, James
and Mills, Gordon B.
and Nguyen, Lam
and Su, Xiaoping
and Verhaak, Roeland
and Wang, Wenyi
and Weinstein, John N.
and Wong, Andrew
and Yang, Yang
and Yao, Jun
and Yao, Rong
and Yoshihara, Kosuke
and Yuan, Yuan
and Yung, Alfred K.
and Zhang, Nianxiang
and Zheng, Siyuan
and Ryan, Michael
and Kane, David W.
and Aksoy, B. Arman
and Ciriello, Giovanni
and Dresdner, Gideon
and Gao, Jianjiong
and Gross, Benjamin
and Jacobsen, Anders
and Kahles, Andre
and Ladanyi, Marc
and Lee, William
and Lehmann, Kjong-Van
and Miller, Martin L.
and Ramirez, Ricardo
and R{\"a}tsch, Gunnar
and Reva, Boris
and Sander, Chris
and Schultz, Nikolaus
and Senbabaoglu, Yasin
and Shen, Ronglai
and Sinha, Rileen
and Sumer, S. Onur
and Sun, Yichao
and Taylor, Barry S.
and Weinhold, Nils
and Fei, Suzanne
and Spellman, Paul
and Benz, Christopher
and Carlin, Daniel
and Cline, Melisssa
and Craft, Brian
and Ellrott, Kyle
and Goldman, Mary
and Haussler, David
and Ma, Singer
and Ng, Sam
and Paull, Evan
and Radenbaugh, Amie
and Salama, Sofie
and Sokolov, Artem
and Stuart, Joshua M.
and Swatloski, Teresa
and Uzunangelov, Vladislav
and Waltman, Peter
and Yau, Christina
and Zhu, Jing
and Hamilton, Stanley R.
and Abbott, Scott
and Abbott, Rachel
and Dees, Nathan D.
and Delehaunty, Kim
and Ding, Li
and Dooling, David J.
and Eldred, Jim M.
and Fronick, Catrina C.
and Fulton, Robert
and Fulton, Lucinda L.
and Kalicki-Veizer, Joelle
and Kanchi, Krishna-Latha
and Kandoth, Cyriac
and Koboldt, Daniel C.
and Larson, David E.
and Ley, Timothy J.
and Lin, Ling
and Lu, Charles
and Magrini, Vincent J.
and Mardis, Elaine R.
and McLellan, Michael D.
and McMichael, Joshua F.
and Miller, Christopher A.
and O'Laughlin, Michelle
and Pohl, Craig
and Schmidt, Heather
and Smith, Scott M.
and Walker, Jason
and Wallis, John W.
and Wendl, Michael C.
and Wilson, Richard K.
and Wylie, Todd
and Zhang, Qunyuan
and Burton, Robert
and Jensen, Mark A.
and Kahn, Ari
and Pihl, Todd
and Pot, David
and Wan, Yunhu
and Levine, Douglas A.
and Black, Aaron D.
and Bowen, Jay
and Network, The Cancer Genome Atlas Research
and Center, Genome Characterization
and Center, Genome Data Analysis
and Center, Sequencing
and Center, Data Coordinating
and Site, Tissue Source
and Center, Biospecimen Core Resource},
title={The Cancer Genome Atlas Pan-Cancer analysis project},
journal={Nature Genetics},
year={2013},
day={01},
volume={45},
number={10},
pages={1113-1120},
abstract={Current clinical practice is organized according to tissue or organ of origin of tumors. Now, The Cancer Genome Atlas (TCGA) Research Network has started to identify genomic and other molecular commonalities among a dozen different types of cancer. Emerging similarities and contrasts will form the basis for targeted therapies of the future and for repurposing existing therapies by molecular rather than histological similarities of the diseases.},
issn={1546-1718},
doi={10.1038/ng.2764},
url={https://doi.org/10.1038/ng.2764}
}

@article{cyclegan_he,
author={Runz, Marlen
and Rusche, Daniel
and Schmidt, Stefan
and Weihrauch, Martin R.
and Hesser, J{\"u}rgen
and Weis, Cleo-Aron},
title={Normalization of HE-stained histological images using cycle consistent generative adversarial networks},
journal={Diagnostic Pathology},
year={2021},
day={06},
volume={16},
number={1},
pages={71},
abstract={Histological images show strong variance (e.g. illumination, color, staining quality) due to differences in image acquisition, tissue processing, staining, etc. This can impede downstream image analysis such as staining intensity evaluation or classification. Methods to reduce these variances are called image normalization techniques.},
issn={1746-1596},
doi={10.1186/s13000-021-01126-y},
url={https://doi.org/10.1186/s13000-021-01126-y}
}

@article{cyclegan_he_2,
      title={Standardized CycleGAN training for unsupervised stain adaptation in invasive carcinoma classification for breast histopathology}, 
      author={Nicolas Nerrienet and Rémy Peyret and Marie Sockeel and Stéphane Sockeel},
      year={2024},
      eprint={2301.13128},
      archivePrefix={arXiv},
      primaryClass={eess.IV},
      url={https://arxiv.org/abs/2301.13128}, 
}












